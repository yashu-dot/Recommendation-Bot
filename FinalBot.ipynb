{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNMdRNzkfj2jVzslggKFUd8"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"GI3jmcv_oO7v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":128},"executionInfo":{"status":"ok","timestamp":1593326141518,"user_tz":-330,"elapsed":111588,"user":{"displayName":"singam bhargavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgDH64Jj6FMqlKPdXPE_n71Cya79IeAP_zywarzg=s64","userId":"07853502214478649639"}},"outputId":"e57b79f0-e579-42d3-a577-11efa47492bd"},"source":["from google.colab import drive\n","drive.mount(\"AIML\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at AIML\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IT0q7Dn0o4VE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593326172128,"user_tz":-330,"elapsed":1304,"user":{"displayName":"singam bhargavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgDH64Jj6FMqlKPdXPE_n71Cya79IeAP_zywarzg=s64","userId":"07853502214478649639"}},"outputId":"7013903c-0159-4b20-be24-9affc054e144"},"source":["cd /content/AIML/My Drive/Colab Notebooks"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/AIML/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fSGFQq3zta-o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":199},"executionInfo":{"status":"ok","timestamp":1593351750427,"user_tz":-330,"elapsed":1009,"user":{"displayName":"singam bhargavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgDH64Jj6FMqlKPdXPE_n71Cya79IeAP_zywarzg=s64","userId":"07853502214478649639"}},"outputId":"903491bc-37c9-4e2b-abe7-97f57e0b1266"},"source":["import random\n","import json\n","import os\n","import re\n","\n","#%%script false\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.corpus import wordnet\n","from nltk import pos_tag\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","import numpy as np\n","import pandas as pd\n","import re\n","from bs4 import BeautifulSoup\n","\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from os.path import join\n","from tqdm import tqdm\n","\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","\n","tqdm.pandas()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JPD4CEF_o_12","colab_type":"code","colab":{}},"source":["#rb_context\n","\n","class Context(object):\n","\n","    def __init__(self,name):\n","        self.lifespan = 2\n","        self.name = name\n","        self.active = False\n","\n","    def activate_context(self):\n","        self.active = True\n","\n","    def deactivate_context(self):\n","        self.active = False\n","\n","        def decrease_lifespan(self):\n","            self.lifespan -= 1\n","            if self.lifespan==0:\n","                self.deactivate_context()\n","\n","class FirstGreeting(Context):\n","\n","    def __init__(self):\n","        self.lifespan = 1\n","        self.name = 'FirstGreeting'\n","        self.active = True\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1kVVyFOEpemx","colab_type":"code","colab":{}},"source":["#rb_actions\n","\n","'''This function masks the entities in user input, and updates the attributes dictionary'''\n","def getattributes(uinput, context, attributes):\n","\n","    # Can use context to context specific attribute fetching\n","    # print(\"getattributes context \", context)\n","    if context.name.startswith('IntentComplete'):\n","        return attributes, uinput\n","    else:\n","        # Code can be optimised here, loading the same files each time suboptimal\n","        files = os.listdir('./entities/')\n","        # Filtering dat files and extracting entity values inside the entities folder\n","        entities = {}\n","        for fil in files:\n","            if fil == \".ipynb_checkpoints\":\n","                continue\n","            lines = open('./entities/'+fil).readlines()\n","            for i, line in enumerate(lines):\n","                lines[i] = line[:-1]\n","            entities[fil[:-4]] = '|'.join(lines)\n","\n","        # Extract entity and update it in attributes dict\n","        for entity in entities:\n","            for i in entities[entity].split('|'):\n","                if i.lower() in uinput.lower():\n","                    attributes[entity] = i\n","\n","        # Masking the entity values $ sign\n","        for entity in entities:\n","            uinput = re.sub(entities[entity], r'$'+entity, uinput, flags=re.IGNORECASE)\n","        #print(\"Files : \",files,\"\\nEntities : \",entities,\"\\nAttributes : \",attributes,\"\\n\")\n","        return attributes, uinput\n","\n","'''Spellcheck and entity extraction functions go here'''\n","def input_processor(user_input, context, attributes, intent):\n","\n","    # uinput = TextBlob(user_input).correct().string\n","\n","    # update the attributes, abstract over the entities in user input\n","    attributes, cleaned_input = getattributes(user_input, context, attributes)\n","\n","    return attributes, cleaned_input\n","\n","'''This function is used to classify the intent'''\n","def intentIdentifier(clean_input, context, current_intent):\n","    clean_input = clean_input.lower()\n","    # print(\"intentIdentifier - clean_input \", clean_input)\n","    '''Word Embedding using Bag of Words'''\n","    pred=bof(clean_input)\n","    '''TODO : YOUR CODE HERE TO CLASSIFY THE INTENT'''\n","    # Scoring Algorithm, can be changed.\n","    #scores = ngrammatch(clean_input)\n","    # choosing here the intent with the highest score\n","    #scores = sorted_by_second = sorted(scores, key=lambda tup: tup[1])\n","    # print('intentIdentifier - scores ', scores)\n","    dfpredict=pd.DataFrame(pred)\n","    classval=dfpredict[0][0]\n","    if classval==0:\n","      score='CabType'\n","    elif classval==1:\n","      score='MovieRecommend'\n","    \n","    if current_intent is None:\n","        if classval == 0:\n","            current_intent = loadIntent('params/newparams.cfg', 'CabType')\n","        if classval==1:\n","            current_intent = loadIntent('params/newparams.cfg', 'MovieRecommend')\n","        else:\n","          current_intent=loadIntent('params/newparams.cfg', score)\n","        print(\"intentIdentifier - current_intent \", current_intent.name)\n","        return current_intent\n","    else:\n","        # If current intent is not none, stick with the ongoing intent\n","        return current_intent\n","\n","def text_normalization(sentence):\n","        lemmatizer = WordNetLemmatizer()\n","        stop=set(stopwords.words('english'))\n","        sentence = str(sentence).lower()\n","        removed_punctuation = re.sub(r'[^a-zA-Z]', ' ', sentence)\n","        tokens = nltk.word_tokenize(removed_punctuation)\n","        lemma = WordNetLemmatizer()\n","        tags_list = pos_tag(tokens, tagset=None)\n","        lemma_words = []\n","        for token, pos_token in tags_list:\n","            if pos_token.startswith('v'):\n","                pos_val = 'v'\n","            elif pos_token.startswith('J'):\n","                pos_val = 'a'\n","            elif pos_token.startswith('R'):\n","                pos_val = 'r'\n","            else:\n","                pos_val = 'n'\n","            lemma_token = lemma.lemmatize(token, pos_val)\n","            lemma_words.append(lemma_token)\n","        return \" \".join(lemma_words)\n","        removed_markup = BeautifulSoup(sentence, 'html.parser').text\n","\n","        tokens = removed_punctuation.lower().split()\n","        removed_stopwords = [w for w in tokens if w not in stop]\n","        lemmatized = [lemmatizer.lemmatize(w) for w in removed_stopwords]\n","        return ' '.join(lemmatized)\n","\n","'''Collects attributes pertaining to the current intent'''\n","def check_required_params(current_intent, attributes, context):\n","\n","    for para in current_intent.params:\n","        if para.required == 'True':\n","            if para.name not in attributes:\n","                # Example of where the context is born\n","                # if para.name=='RegNo':\n","                    # context = GetRegNo()\n","                # returning a random prompt from available choices.\n","                return random.choice(para.prompts), context\n","\n","    return None, context\n","\n","def check_actions(current_intent, attributes, context):\n","    '''This function performs the action for the intent\n","    as mentioned in the intent config file'''\n","    '''Performs actions pertaining to current intent\n","    for action in current_intent.actions:\n","        if action.contexts_satisfied(active_contexts):\n","            return perform_action()\n","    '''\n","\n","    context = IntentComplete()\n","    #print(return 'action: ' + current_intent.action, context)\n","    return current_intent.action, context\n","\n","def loadIntent(path, intent):\n","    with open(path) as file_intent:\n","        dat = json.load(file_intent)\n","        intent = dat[intent]\n","        return Intent(intent['intentname'], intent['parameters'], intent['actions'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MM46_2JCrcqF","colab_type":"code","colab":{}},"source":["#rb_intents\n","\n","class Intent(object):\n","    # intent name, parameters and actions\n","    def __init__(self, name, params, action):\n","        self.name = name\n","        self.action = action\n","        self.params = []\n","        for param in params:\n","            # print param['required']\n","            self.params += [Parameter(param)]\n","\n","class IntentComplete(Context):\n","\n","    def __init__(self):\n","        self.lifespan = 1\n","        self.name = 'IntentComplete'\n","        self.active = True\n","\n","class Parameter():\n","    def __init__(self, info):\n","        self.name = info['name']\n","        self.placeholder = info['placeholder']\n","        self.prompts = info['prompts']\n","        self.required = info['required']\n","        self.context = info['context']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T9cSsMrjrouT","colab_type":"code","colab":{}},"source":["#rb_session\n","class Session:\n","    '''Initialise a default session'''\n","    def __init__(self, attributes=None, active_contexts=[FirstGreeting(), IntentComplete() ]):\n","\n","        # Active contexts not used yet, can use it to have multiple contexts\n","        self.active_contexts = active_contexts\n","\n","        # Contexts are flags which control dialogue flow\n","        self.context = FirstGreeting()\n","\n","        # Intent tracks the current state of dialogue\n","        #self.current_intent = First_Greeting()\n","        self.current_intent = None\n","\n","        # attributes hold the information collected over the conversation\n","        self.attributes = {}\n","\n","    '''Not used yet, but is intended to maintain active contexts'''\n","    def update_contexts(self):\n","\n","        for context in self.active_contexts:\n","            if context.active:\n","                context.decrease_lifespan()\n","\n","    '''Generate response to user input'''\n","    def reply(self, user_input):\n","        #print(\"User Input  \",user_input)\n","        self.attributes, clean_input = input_processor(user_input, self.context, self.attributes, self.current_intent)\n","        #print(\"In Session  \",clean_input)\n","\n","        self.current_intent = intentIdentifier(clean_input, self.context, self.current_intent)\n","\n","        prompt, self.context = check_required_params(self.current_intent, self.attributes, self.context)\n","\n","        # prompt is None means all parameters satisfied, perform the intent action\n","        if prompt is None:\n","            if self.context.name != 'IntentComplete':\n","                prompt, self.context = check_actions(self.current_intent, self.attributes, self.context)\n","                # print(\"reply - prompt \", prompt, \" context \", self.context)\n","                '''TODO : YOUR CODE HERE TO GET RECOMMENDATION BASED ON THE ENTFITY VALUES'''\n","                if prompt == \"CabService\" :\n","                    print(\"You booked Ola Mini\")\n","                elif prompt == \"MovieService\" :\n","                    print(\"Watch Krishna and His Leela. Enjoy!\")\n","                prompt = \"BOT: Hi! How may I assist you?\"\n","\n","        # Resets the state after the Intent is complete\n","        if self.context.name == 'IntentComplete':\n","            self.attributes = {}\n","            self.context = FirstGreeting()\n","            self.current_intent = None\n","\n","        return prompt\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zy6ER623sZzS","colab_type":"code","colab":{}},"source":["class GetRegNo(Context):\n","\n","    def __init__(self):\n","        print('Hi')\n","        self.lifespan = 1\n","        self.name = 'GetRegNo'\n","        self.active = True\n","\n","class SpellConformation(Context):\n","\n","    def __init__(self,index,CorrectWord,user_input,context):\n","        self.lifespan = 1\n","        self.name = 'SpellConformation'\n","        self.active = True\n","        self.index = index\n","        self.correct = CorrectWord\n","        self.tobecorrected = user_input\n","        self.contexttobestored = context"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ubeBeWw8PoY","colab_type":"code","colab":{}},"source":["def bof(clean_input):\n","    p = pd.read_csv('corpus.csv')\n","    df = pd.DataFrame(p)\n","    df['intents_cleaned'] = df['intents'].progress_apply(text_normalization)\n","\n","    vectorizer = CountVectorizer()\n","    train_features = vectorizer.fit_transform(df['intents_cleaned'])\n","    train_features = train_features.toarray()\n","\n","    vocab = vectorizer.get_feature_names()\n","    df_bow = pd.DataFrame(train_features, columns=vocab)  # list of words\n","    \n","    lemmatizer = WordNetLemmatizer()\n","    stop=stopwords.words('english')\n","\n","    query = clean_input\n","    q = []\n","    a = query.split()\n","    for i in a:\n","        if i in stop:\n","            continue\n","        else:\n","            q.append(i)\n","        b = \" \".join(q)\n","\n","    ql = text_normalization(b)\n","    q_bow = vectorizer.transform([ql]).toarray()\n","    #print(q_bow)\n","    pred=classification_svm(df,q_bow,train_features)\n","    dfp=pd.DataFrame(pred)\n","    return dfp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c_Kin7Wh84KU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"status":"ok","timestamp":1593348649195,"user_tz":-330,"elapsed":1056,"user":{"displayName":"singam bhargavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgDH64Jj6FMqlKPdXPE_n71Cya79IeAP_zywarzg=s64","userId":"07853502214478649639"}},"outputId":"2c876149-e4b6-4337-9ec5-97433a823488"},"source":["#prediction=bof('watch a movie')\n","#prediction"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","\n","\n","100%|██████████| 40/40 [00:00<00:00, 869.18it/s]"],"name":"stderr"},{"output_type":"stream","text":["   0\n","0  1\n","   0\n","0  1\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0\n","0  1"]},"metadata":{"tags":[]},"execution_count":127}]},{"cell_type":"code","metadata":{"id":"8ZT4T49Iw8sD","colab_type":"code","colab":{}},"source":["#KNN ALgorithm\n","\n","def classification_svm(df,q_bow,train_features):\n","  df['classes'] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","                     1, 1, 1, 1, 1, 1, 1]\n","  svm=SVC()\n","  svm.fit(train_features, df['classes'])\n","  pred = svm.predict(q_bow)\n","  dfp = pd.DataFrame(pred)\n","  #print(dfp)\n","  return dfp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A5vDwbVJ7sD1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593347895221,"user_tz":-330,"elapsed":968,"user":{"displayName":"singam bhargavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgDH64Jj6FMqlKPdXPE_n71Cya79IeAP_zywarzg=s64","userId":"07853502214478649639"}},"outputId":"ec7dbb00-d939-4438-f947-450514fbc68f"},"source":["df = pd.DataFrame([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","                     1, 1, 1, 1, 1, 1, 1])\n","df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(40, 1)"]},"metadata":{"tags":[]},"execution_count":99}]},{"cell_type":"code","metadata":{"id":"62sNDaLIszTJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":872},"executionInfo":{"status":"ok","timestamp":1593352126049,"user_tz":-330,"elapsed":80239,"user":{"displayName":"singam bhargavi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgDH64Jj6FMqlKPdXPE_n71Cya79IeAP_zywarzg=s64","userId":"07853502214478649639"}},"outputId":"08b26ec9-a4b5-4f53-b095-f2c7beb9a2b7"},"source":["#rb_main\n","session = Session()\n","\n","print('BOT: Hi! How may I assist you?')\n","\n","while True:\n","    \n","    inp = input('User: ')\n","    if inp == \"exit\" :\n","        break\n","    print('BOT:', session.reply(inp))"],"execution_count":166,"outputs":[{"output_type":"stream","text":["BOT: Hi! How may I assist you?\n","User: cab service\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","100%|██████████| 40/40 [00:00<00:00, 1033.16it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["intentIdentifier - current_intent  CabType\n","BOT: What's the pick up point?\n","User: bhel\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","100%|██████████| 40/40 [00:00<00:00, 1100.84it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["BOT: What is the destination u want to reach?\n","User: ecil\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","100%|██████████| 40/40 [00:00<00:00, 1012.52it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["BOT: What is the price range u want?\n","User: 410\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","100%|██████████| 40/40 [00:00<00:00, 992.59it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["BOT: Would you want Covid Care facility?\n","User: available\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","100%|██████████| 40/40 [00:00<00:00, 1156.95it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["You booked Ola Mini\n","BOT: BOT: Hi! How may I assist you?\n","User: movie search\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","100%|██████████| 40/40 [00:00<00:00, 983.04it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["intentIdentifier - current_intent  CabType\n","BOT: What's the pick up point?\n","User: exit\n"],"name":"stdout"}]}]}